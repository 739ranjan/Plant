{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97011fc6-b58d-477c-90c5-ae83ab191433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0507ef81-aabb-4e31-b553-a97011b918f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model architecture (either by defining from scratch or using a pre-defined AlexNet implementation)\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(64, (11, 11), strides=(4, 4), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    layers.Conv2D(192, (5, 5), activation='relu'),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    layers.Conv2D(384, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((3, 3), strides=(2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dense(4096, activation='relu'),\n",
    "    layers.Dense(42, activation='softmax')  # Adjust num_classes based on your dataset\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49c7779-ce9d-4abd-918b-be89e9461f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile your model with the legacy Keras optimizer\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.SGD(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5489374b-4b4a-47c7-9953-b89393021e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image data generators for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4d740f-0cc0-4e97-a581-5eb6f587e563",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='/Users/sumitshaw/data_science/NewDatasets/train'\n",
    "val_dir='/Users/sumitshaw/data_science/NewDatasets/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfa3a4d0-9988-4bfc-aa53-175ae48a58e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set batch size and image size\n",
    "batch_size = 32\n",
    "image_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50678f6a-84c3-46b1-9d60-4ec72531c3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70779 images belonging to 42 classes.\n",
      "Found 18019 images belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "# Load training and validation datasets using flow_from_directory\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_dataset = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7add1cec-2059-41ea-aae6-6a838ff65a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/88\n",
      "2212/2212 [==============================] - 974s 440ms/step - loss: 3.7181 - accuracy: 0.0574 - val_loss: 3.6787 - val_accuracy: 0.0590\n",
      "Epoch 2/88\n",
      "2212/2212 [==============================] - 1009s 456ms/step - loss: 3.6223 - accuracy: 0.0607 - val_loss: 3.6198 - val_accuracy: 0.0590\n",
      "Epoch 3/88\n",
      "2212/2212 [==============================] - 1028s 465ms/step - loss: 3.5799 - accuracy: 0.0656 - val_loss: 3.5299 - val_accuracy: 0.0776\n",
      "Epoch 4/88\n",
      "2212/2212 [==============================] - 1047s 473ms/step - loss: 3.3010 - accuracy: 0.1127 - val_loss: 3.0492 - val_accuracy: 0.1615\n",
      "Epoch 5/88\n",
      "2212/2212 [==============================] - 1058s 478ms/step - loss: 2.7887 - accuracy: 0.2062 - val_loss: 2.6583 - val_accuracy: 0.2450\n",
      "Epoch 6/88\n",
      "2212/2212 [==============================] - 1102s 498ms/step - loss: 2.4348 - accuracy: 0.2781 - val_loss: 2.4018 - val_accuracy: 0.3070\n",
      "Epoch 7/88\n",
      "2212/2212 [==============================] - 1109s 501ms/step - loss: 2.1679 - accuracy: 0.3431 - val_loss: 2.0695 - val_accuracy: 0.3962\n",
      "Epoch 8/88\n",
      "2212/2212 [==============================] - 1058s 478ms/step - loss: 1.9283 - accuracy: 0.4119 - val_loss: 1.8164 - val_accuracy: 0.4500\n",
      "Epoch 9/88\n",
      "2212/2212 [==============================] - 1042s 471ms/step - loss: 1.6811 - accuracy: 0.4797 - val_loss: 1.6111 - val_accuracy: 0.5131\n",
      "Epoch 10/88\n",
      "2212/2212 [==============================] - 1043s 471ms/step - loss: 1.4948 - accuracy: 0.5321 - val_loss: 1.4921 - val_accuracy: 0.5471\n",
      "Epoch 11/88\n",
      "2212/2212 [==============================] - 1039s 470ms/step - loss: 1.3591 - accuracy: 0.5724 - val_loss: 1.3945 - val_accuracy: 0.5816\n",
      "Epoch 12/88\n",
      "2212/2212 [==============================] - 1030s 466ms/step - loss: 1.2457 - accuracy: 0.6055 - val_loss: 1.3477 - val_accuracy: 0.5914\n",
      "Epoch 13/88\n",
      "2212/2212 [==============================] - 1030s 466ms/step - loss: 1.1430 - accuracy: 0.6381 - val_loss: 1.2032 - val_accuracy: 0.6415\n",
      "Epoch 14/88\n",
      "2212/2212 [==============================] - 1032s 467ms/step - loss: 1.0458 - accuracy: 0.6644 - val_loss: 1.1280 - val_accuracy: 0.6681\n",
      "Epoch 15/88\n",
      "2212/2212 [==============================] - 1033s 467ms/step - loss: 0.9554 - accuracy: 0.6925 - val_loss: 1.0396 - val_accuracy: 0.6982\n",
      "Epoch 16/88\n",
      "2212/2212 [==============================] - 1029s 465ms/step - loss: 0.8837 - accuracy: 0.7164 - val_loss: 1.0533 - val_accuracy: 0.6986\n",
      "Epoch 17/88\n",
      "2212/2212 [==============================] - 1026s 464ms/step - loss: 0.8146 - accuracy: 0.7360 - val_loss: 0.9438 - val_accuracy: 0.7308\n",
      "Epoch 18/88\n",
      "2212/2212 [==============================] - 1028s 465ms/step - loss: 0.7561 - accuracy: 0.7521 - val_loss: 0.9826 - val_accuracy: 0.7198\n",
      "Epoch 19/88\n",
      "2212/2212 [==============================] - 1050s 475ms/step - loss: 0.7081 - accuracy: 0.7681 - val_loss: 0.8365 - val_accuracy: 0.7637\n",
      "Epoch 20/88\n",
      "2212/2212 [==============================] - 1060s 479ms/step - loss: 0.6659 - accuracy: 0.7805 - val_loss: 0.8538 - val_accuracy: 0.7569\n",
      "Epoch 21/88\n",
      "2212/2212 [==============================] - 1062s 480ms/step - loss: 0.6226 - accuracy: 0.7955 - val_loss: 0.7630 - val_accuracy: 0.7914\n",
      "Epoch 22/88\n",
      "2212/2212 [==============================] - 1062s 480ms/step - loss: 0.5879 - accuracy: 0.8056 - val_loss: 0.7671 - val_accuracy: 0.7866\n",
      "Epoch 23/88\n",
      "2212/2212 [==============================] - 1024s 463ms/step - loss: 0.5537 - accuracy: 0.8168 - val_loss: 0.7164 - val_accuracy: 0.7998\n",
      "Epoch 24/88\n",
      "2212/2212 [==============================] - 1024s 463ms/step - loss: 0.5257 - accuracy: 0.8262 - val_loss: 0.8085 - val_accuracy: 0.7756\n",
      "Epoch 25/88\n",
      "2212/2212 [==============================] - 1029s 465ms/step - loss: 0.4959 - accuracy: 0.8340 - val_loss: 0.7223 - val_accuracy: 0.8071\n",
      "Epoch 26/88\n",
      "2212/2212 [==============================] - 1029s 465ms/step - loss: 0.4724 - accuracy: 0.8422 - val_loss: 0.6488 - val_accuracy: 0.8263\n",
      "Epoch 27/88\n",
      "2212/2212 [==============================] - 1030s 466ms/step - loss: 0.4533 - accuracy: 0.8482 - val_loss: 0.6333 - val_accuracy: 0.8182\n",
      "Epoch 28/88\n",
      "2212/2212 [==============================] - 1034s 468ms/step - loss: 0.4301 - accuracy: 0.8550 - val_loss: 0.6825 - val_accuracy: 0.8088\n",
      "Epoch 29/88\n",
      "2212/2212 [==============================] - 1038s 469ms/step - loss: 0.4178 - accuracy: 0.8600 - val_loss: 0.6210 - val_accuracy: 0.8364\n",
      "Epoch 30/88\n",
      "2212/2212 [==============================] - 1039s 470ms/step - loss: 0.3986 - accuracy: 0.8669 - val_loss: 0.6290 - val_accuracy: 0.8351\n",
      "Epoch 31/88\n",
      "2212/2212 [==============================] - 1042s 471ms/step - loss: 0.3848 - accuracy: 0.8713 - val_loss: 0.5783 - val_accuracy: 0.8507\n",
      "Epoch 32/88\n",
      "2212/2212 [==============================] - 1044s 472ms/step - loss: 0.3691 - accuracy: 0.8759 - val_loss: 0.6047 - val_accuracy: 0.8478\n",
      "Epoch 33/88\n",
      "2212/2212 [==============================] - 1041s 471ms/step - loss: 0.3539 - accuracy: 0.8803 - val_loss: 0.6034 - val_accuracy: 0.8421\n",
      "Epoch 34/88\n",
      "2212/2212 [==============================] - 1098s 496ms/step - loss: 0.3413 - accuracy: 0.8835 - val_loss: 0.5752 - val_accuracy: 0.8596\n",
      "Epoch 35/88\n",
      "2212/2212 [==============================] - 1118s 505ms/step - loss: 0.3320 - accuracy: 0.8868 - val_loss: 0.5709 - val_accuracy: 0.8480\n",
      "Epoch 36/88\n",
      "2212/2212 [==============================] - 1104s 499ms/step - loss: 0.3207 - accuracy: 0.8922 - val_loss: 0.5920 - val_accuracy: 0.8488\n",
      "Epoch 37/88\n",
      "2212/2212 [==============================] - 1096s 495ms/step - loss: 0.3049 - accuracy: 0.8959 - val_loss: 0.5607 - val_accuracy: 0.8586\n",
      "Epoch 38/88\n",
      "2212/2212 [==============================] - 1096s 496ms/step - loss: 0.2978 - accuracy: 0.8983 - val_loss: 0.5187 - val_accuracy: 0.8597\n",
      "Epoch 39/88\n",
      "2212/2212 [==============================] - 1103s 499ms/step - loss: 0.2863 - accuracy: 0.9026 - val_loss: 0.5401 - val_accuracy: 0.8654\n",
      "Epoch 40/88\n",
      "2212/2212 [==============================] - 1108s 501ms/step - loss: 0.2806 - accuracy: 0.9044 - val_loss: 0.5312 - val_accuracy: 0.8720\n",
      "Epoch 41/88\n",
      "2212/2212 [==============================] - 1113s 503ms/step - loss: 0.2699 - accuracy: 0.9074 - val_loss: 0.5316 - val_accuracy: 0.8680\n",
      "Epoch 42/88\n",
      "2212/2212 [==============================] - 1121s 507ms/step - loss: 0.2637 - accuracy: 0.9083 - val_loss: 0.5287 - val_accuracy: 0.8713\n",
      "Epoch 43/88\n",
      "2212/2212 [==============================] - 1130s 511ms/step - loss: 0.2551 - accuracy: 0.9122 - val_loss: 0.5446 - val_accuracy: 0.8734\n",
      "Epoch 44/88\n",
      "2212/2212 [==============================] - 1185s 536ms/step - loss: 0.2507 - accuracy: 0.9130 - val_loss: 0.5214 - val_accuracy: 0.8743\n",
      "Epoch 45/88\n",
      "2212/2212 [==============================] - 1221s 552ms/step - loss: 0.2405 - accuracy: 0.9170 - val_loss: 0.5150 - val_accuracy: 0.8733\n",
      "Epoch 46/88\n",
      "2212/2212 [==============================] - 1211s 548ms/step - loss: 0.2352 - accuracy: 0.9177 - val_loss: 0.5314 - val_accuracy: 0.8747\n",
      "Epoch 47/88\n",
      "2212/2212 [==============================] - 1249s 564ms/step - loss: 0.2339 - accuracy: 0.9181 - val_loss: 0.5276 - val_accuracy: 0.8762\n",
      "Epoch 48/88\n",
      "2212/2212 [==============================] - 1214s 549ms/step - loss: 0.2230 - accuracy: 0.9218 - val_loss: 0.5004 - val_accuracy: 0.8756\n",
      "Epoch 49/88\n",
      "2212/2212 [==============================] - 1171s 530ms/step - loss: 0.2152 - accuracy: 0.9257 - val_loss: 0.5649 - val_accuracy: 0.8750\n",
      "Epoch 50/88\n",
      "2212/2212 [==============================] - 1191s 538ms/step - loss: 0.2111 - accuracy: 0.9266 - val_loss: 0.4886 - val_accuracy: 0.8818\n",
      "Epoch 51/88\n",
      "2212/2212 [==============================] - 1201s 543ms/step - loss: 0.2071 - accuracy: 0.9271 - val_loss: 0.5205 - val_accuracy: 0.8762\n",
      "Epoch 52/88\n",
      "2212/2212 [==============================] - 1212s 548ms/step - loss: 0.2017 - accuracy: 0.9301 - val_loss: 0.5126 - val_accuracy: 0.8836\n",
      "Epoch 53/88\n",
      "2212/2212 [==============================] - 1166s 527ms/step - loss: 0.1968 - accuracy: 0.9309 - val_loss: 0.5000 - val_accuracy: 0.8778\n",
      "Epoch 54/88\n",
      "2212/2212 [==============================] - 1102s 498ms/step - loss: 0.1922 - accuracy: 0.9331 - val_loss: 0.4720 - val_accuracy: 0.8883\n",
      "Epoch 55/88\n",
      "2212/2212 [==============================] - 1104s 499ms/step - loss: 0.1888 - accuracy: 0.9336 - val_loss: 0.5308 - val_accuracy: 0.8776\n",
      "Epoch 56/88\n",
      "2212/2212 [==============================] - 1113s 503ms/step - loss: 0.1821 - accuracy: 0.9353 - val_loss: 0.5113 - val_accuracy: 0.8886\n",
      "Epoch 57/88\n",
      "2212/2212 [==============================] - 1122s 507ms/step - loss: 0.1814 - accuracy: 0.9359 - val_loss: 0.5352 - val_accuracy: 0.8856\n",
      "Epoch 58/88\n",
      "2212/2212 [==============================] - 1193s 539ms/step - loss: 0.1760 - accuracy: 0.9377 - val_loss: 0.4974 - val_accuracy: 0.8910\n",
      "Epoch 59/88\n",
      "2212/2212 [==============================] - 1223s 553ms/step - loss: 0.1734 - accuracy: 0.9381 - val_loss: 0.5245 - val_accuracy: 0.8906\n",
      "Epoch 60/88\n",
      "2212/2212 [==============================] - 1203s 544ms/step - loss: 0.1672 - accuracy: 0.9405 - val_loss: 0.4906 - val_accuracy: 0.8947\n",
      "Epoch 61/88\n",
      "2212/2212 [==============================] - 1219s 551ms/step - loss: 0.1632 - accuracy: 0.9418 - val_loss: 0.5104 - val_accuracy: 0.8945\n",
      "Epoch 62/88\n",
      "2212/2212 [==============================] - 1265s 572ms/step - loss: 0.1603 - accuracy: 0.9429 - val_loss: 0.4988 - val_accuracy: 0.8978\n",
      "Epoch 63/88\n",
      "2212/2212 [==============================] - 1321s 597ms/step - loss: 0.1566 - accuracy: 0.9429 - val_loss: 0.4825 - val_accuracy: 0.8965\n",
      "Epoch 64/88\n",
      "2212/2212 [==============================] - 1233s 557ms/step - loss: 0.1528 - accuracy: 0.9446 - val_loss: 0.5496 - val_accuracy: 0.8861\n",
      "Epoch 65/88\n",
      "2212/2212 [==============================] - 1200s 543ms/step - loss: 0.1486 - accuracy: 0.9469 - val_loss: 0.5322 - val_accuracy: 0.8906\n",
      "Epoch 66/88\n",
      "2212/2212 [==============================] - 1205s 545ms/step - loss: 0.1488 - accuracy: 0.9466 - val_loss: 0.5599 - val_accuracy: 0.8928\n",
      "Epoch 67/88\n",
      "2212/2212 [==============================] - 1177s 532ms/step - loss: 0.1436 - accuracy: 0.9481 - val_loss: 0.4673 - val_accuracy: 0.9015\n",
      "Epoch 68/88\n",
      "2212/2212 [==============================] - 1127s 509ms/step - loss: 0.1419 - accuracy: 0.9493 - val_loss: 0.4982 - val_accuracy: 0.8937\n",
      "Epoch 69/88\n",
      "2212/2212 [==============================] - 1103s 499ms/step - loss: 0.1401 - accuracy: 0.9492 - val_loss: 0.5137 - val_accuracy: 0.8964\n",
      "Epoch 70/88\n",
      "2212/2212 [==============================] - 1087s 492ms/step - loss: 0.1357 - accuracy: 0.9517 - val_loss: 0.5112 - val_accuracy: 0.8944\n",
      "Epoch 71/88\n",
      "2212/2212 [==============================] - 1080s 488ms/step - loss: 0.1334 - accuracy: 0.9522 - val_loss: 0.5336 - val_accuracy: 0.9010\n",
      "Epoch 72/88\n",
      "2212/2212 [==============================] - 1073s 485ms/step - loss: 0.1308 - accuracy: 0.9534 - val_loss: 0.5468 - val_accuracy: 0.8959\n",
      "Epoch 73/88\n",
      "2212/2212 [==============================] - 1071s 484ms/step - loss: 0.1279 - accuracy: 0.9535 - val_loss: 0.4855 - val_accuracy: 0.8968\n",
      "Epoch 74/88\n",
      "2212/2212 [==============================] - 1053s 476ms/step - loss: 0.1256 - accuracy: 0.9549 - val_loss: 0.4909 - val_accuracy: 0.9015\n",
      "Epoch 75/88\n",
      "2212/2212 [==============================] - 1071s 484ms/step - loss: 0.1229 - accuracy: 0.9555 - val_loss: 0.5380 - val_accuracy: 0.8976\n",
      "Epoch 76/88\n",
      "2212/2212 [==============================] - 1091s 493ms/step - loss: 0.1199 - accuracy: 0.9560 - val_loss: 0.5120 - val_accuracy: 0.9024\n",
      "Epoch 77/88\n",
      "2212/2212 [==============================] - 1080s 488ms/step - loss: 0.1198 - accuracy: 0.9564 - val_loss: 0.6003 - val_accuracy: 0.8780\n",
      "Epoch 78/88\n",
      "2212/2212 [==============================] - 1078s 487ms/step - loss: 0.1153 - accuracy: 0.9579 - val_loss: 0.5634 - val_accuracy: 0.8910\n",
      "Epoch 79/88\n",
      "2212/2212 [==============================] - 1082s 489ms/step - loss: 0.1126 - accuracy: 0.9592 - val_loss: 0.4999 - val_accuracy: 0.9079\n",
      "Epoch 80/88\n",
      "2212/2212 [==============================] - 1073s 485ms/step - loss: 0.1117 - accuracy: 0.9590 - val_loss: 0.4919 - val_accuracy: 0.9059\n",
      "Epoch 81/88\n",
      "2212/2212 [==============================] - 1059s 479ms/step - loss: 0.1119 - accuracy: 0.9596 - val_loss: 0.4985 - val_accuracy: 0.9061\n",
      "Epoch 82/88\n",
      "2212/2212 [==============================] - 1116s 505ms/step - loss: 0.1095 - accuracy: 0.9596 - val_loss: 0.5692 - val_accuracy: 0.8923\n",
      "Epoch 83/88\n",
      "2212/2212 [==============================] - 1134s 512ms/step - loss: 0.1051 - accuracy: 0.9614 - val_loss: 0.5276 - val_accuracy: 0.9032\n",
      "Epoch 84/88\n",
      "2212/2212 [==============================] - 1113s 503ms/step - loss: 0.1036 - accuracy: 0.9625 - val_loss: 0.5234 - val_accuracy: 0.9009\n",
      "Epoch 85/88\n",
      "2212/2212 [==============================] - 1098s 496ms/step - loss: 0.1015 - accuracy: 0.9629 - val_loss: 0.6086 - val_accuracy: 0.8973\n",
      "Epoch 86/88\n",
      "2212/2212 [==============================] - 1060s 479ms/step - loss: 0.1011 - accuracy: 0.9629 - val_loss: 0.5464 - val_accuracy: 0.9003\n",
      "Epoch 87/88\n",
      "2212/2212 [==============================] - 1044s 472ms/step - loss: 0.1004 - accuracy: 0.9627 - val_loss: 0.5256 - val_accuracy: 0.9102\n",
      "Epoch 88/88\n",
      "2212/2212 [==============================] - 1042s 471ms/step - loss: 0.0946 - accuracy: 0.9655 - val_loss: 0.5250 - val_accuracy: 0.9088\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x280a9d550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can proceed with training your model using model.fit\n",
    "model.fit(train_dataset, epochs=88, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87cf5947-cb90-4cf6-9de4-89165da11fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5527dee6-52bb-41f9-ab1b-9c0b5a2307ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at alexnet.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the saved model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malexnet.h5\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/saving_api.py:262\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[1;32m    255\u001b[0m         filepath,\n\u001b[1;32m    256\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[1;32m    258\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[1;32m    259\u001b[0m     )\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Legacy case.\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_sm_saving_lib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/saving/legacy/save.py:234\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[0;32m--> 234\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[1;32m    235\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m         )\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[1;32m    239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[1;32m    240\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[1;32m    241\u001b[0m         )\n",
      "\u001b[0;31mOSError\u001b[0m: No file or directory found at alexnet.h5"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = tf.keras.models.load_model(\"alexnet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e7848b-2813-48a2-863e-48243388663b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
